{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### references\n",
    "\n",
    "bishop pg 690 \n",
    "bishop pg 74\n",
    "prince pg 38 - ML estimation of params of categorical\n",
    "prince pg 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Distribution\n",
    "\n",
    "Lets consider fitting the categorical distribution, which is a discrete distribution over $K$ outcomes, which we'll number $1$ through $K$. The probability of each category is represented with parameter $\\theta_{k}$. For it to be a valid probability distribution, we clearly need $\\theta_{k} \\ge 0$ and $\\sum_{k} \\theta_{k} = 1$. We'll represent each observation $\\mathbf{x}$ as a 1-of-K encoding, i.e, a vector where one of the entries is 1 and the rest are 0. under this model, the probability of an observation can be written in the following form:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x};\\pmb{\\theta}) = \\prod_{k=1}^K \\theta_{k}^{x_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the Probability of an Observation\n",
    "\n",
    "even though this is not part of the homework, lets compute the probabilty of a single observation given some parameters. suppose we are trying to model a biased 6-sided die; the die is biased toward landing on the number 4, all other sides have equal probability. assuming this, then, a possible set of parameter values might be:\n",
    "\n",
    "$$\n",
    "\\theta_1 = 0.1 \\\\\n",
    "\\theta_2 = 0.1 \\\\\n",
    "\\theta_3 = 0.1 \\\\\n",
    "\\theta_4 = 0.5 \\\\\n",
    "\\theta_5 = 0.1 \\\\\n",
    "\\theta_6 = 0.1\n",
    "$$\n",
    "\n",
    "for brevity, the six thetas are combined into a parameter vector $\\pmb{\\theta}$:\n",
    "\n",
    "$$\n",
    "\\pmb{\\theta} = \\{ \\theta_1, \\theta_2, \\theta_3, \\theta_4, \\theta_5, \\theta_6 \\}\n",
    "$$\n",
    "\n",
    "suppose we roll this die and observe the following $\\mathbf{x}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = (1,0,0,0,0,0)^{T}\n",
    "$$\n",
    "\n",
    "lets expand $p(\\mathbf{x};\\pmb{\\theta})$ with all values substituted in:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} = (1,0,0,0,0,0)^{T}; \n",
    "\\pmb{\\theta} = \\{ \\theta_1, \\theta_2, \\theta_3, \\theta_4, \\theta_5, \\theta_6 \\})\n",
    "$$\n",
    "$$\n",
    "= (\\theta_{1}^{x_1})(\\theta_{2}^{x_2})(\\theta_{3}^{x_3})(\\theta_{4}^{x_4})(\\theta_{5}^{x_5})(\\theta_{6}^{x_6})\n",
    "$$\n",
    "$$\n",
    "= (0.1^1)(0.1^0)(0.1^0)(0.5^0)(0.1^0)(0.1^0)\n",
    "$$\n",
    "$$\n",
    "= (0.1)(1)(1)(1)(1)(1)\n",
    "$$\n",
    "$$\n",
    "= 0.1\n",
    "$$\n",
    "\n",
    "notice how the 1-of-K encoding affects the fully expanded PMF; when the kth component of the observation vector is zero, the kth factor of the PMF is 1. when the kth component of the observation vector is one, the kth factor of the PMF is $\\theta_k$. Here is the same computation for a different observation:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} = (0,0,0,1,0,0)^{T}; \n",
    "\\pmb{\\theta} = \\{ \\theta_1, \\theta_2, \\theta_3, \\theta_4, \\theta_5, \\theta_6 \\})\n",
    "$$\n",
    "$$\n",
    "= (\\theta_{1}^{x_1})(\\theta_{2}^{x_2})(\\theta_{3}^{x_3})(\\theta_{4}^{x_4})(\\theta_{5}^{x_5})(\\theta_{6}^{x_6})\n",
    "$$\n",
    "$$\n",
    "= (0.1^0)(0.1^0)(0.1^0)(0.5^1)(0.1^0)(0.1^0)\n",
    "$$\n",
    "$$\n",
    "= (1)(1)(1)(0.5)(1)(1)\n",
    "$$\n",
    "$$\n",
    "= 0.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HW part a1\n",
    "\n",
    "Determine the formula for the maximum likelihood estimate of the parameters in terms of the counts \n",
    "$N_k = \\sum_{i} x_k^{(i)}$ of all the outcomes. You may assume all of the counts are nonzero. Note that your solution needs to obey the constrains $\\theta_k \\ge 0$ and $\\sum_{k} \\theta_{k} = 1$. see kahn academy lecture [here](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/lagrange-multipliers-and-constrained-optimization/v/constrained-optimization-introduction).\n",
    "\n",
    "given $I$ independent categoricaly distributed observations, the likelihood function is defined as the product of the PMF evaluated at each observation:\n",
    "\n",
    "$$\n",
    "l(\\mathbf{x}_1,\\mathbf{x}_2,...,\\mathbf{x}_N;\\pmb{\\theta}) = \n",
    "p(\\mathbf{x}_1;\\pmb{\\theta})p(\\mathbf{x}_2;\\pmb{\\theta})...p(\\mathbf{x}_I;\\pmb{\\theta}) \\\\\n",
    "$$\n",
    "$$ \n",
    "= \\prod_{i=1}^{I} p(\\mathbf{x}_i;\\pmb{\\theta})\n",
    "$$\n",
    "$$ \n",
    "= \\prod_{i=1}^{I} \\prod_{k=1}^K \\theta_{k}^{x_{k}^{(i)}}\n",
    "$$\n",
    "\n",
    "commutativity gives us\n",
    "\n",
    "$$\n",
    "= \\prod_{k=1}^K \\prod_{i=1}^{I} \\theta_{k}^{x_{k}^{(i)}}\n",
    "$$\n",
    "\n",
    "expand this a bit\n",
    "\n",
    "$$\n",
    "= \\prod_{k=1}^K \\theta_{k}^{x_{k}^{(1)}}\\theta_{k}^{x_{k}^{(2)}}...\\theta_{k}^{x_{k}^{(I)}}\n",
    "$$\n",
    "\n",
    "using properties of exponents\n",
    "\n",
    "$$\n",
    "= \\prod_{k=1}^K \\theta_{k}^{( x_{k}^{(1)} + x_{k}^{(2)} + ... + x_{k}^{(I)} )}\n",
    "$$\n",
    "\n",
    "using more formal notation\n",
    "\n",
    "$$\n",
    "= \\prod_{k=1}^K \\theta_{k}^{(\\sum_{i}^I x_k^{(i)})}\n",
    "$$\n",
    "\n",
    "we let $N_k = \\sum_{i} x_k^{(i)}$ as prescribed above\n",
    "\n",
    "$$\n",
    "= \\prod_{k=1}^K \\theta_{k}^{N_k}\n",
    "$$\n",
    "\n",
    "we must find the $\\theta_k$s that maximize this expression. in typical fashion, we maximize the log of this expression:\n",
    "\n",
    "$$\n",
    "ln \\prod_{k=1}^K \\theta_{k}^{N_k}\n",
    "$$\n",
    "\n",
    "log of a product of terms is the sum of the log of the terms\n",
    "\n",
    "$$\n",
    "= \\sum_{k=1}^K ln(\\theta_{k}^{N_k})\n",
    "$$\n",
    "\n",
    "using property $ln(x^n) = n\\ ln (x)$ \n",
    "\n",
    "$$\n",
    "= \\sum_{k=1}^K N_k\\ ln(\\theta_{k})\n",
    "$$\n",
    "\n",
    "TODO: still need to show that the ML estimate obeys constrains of categorical distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HW part 1b\n",
    "\n",
    "Now consider Bayesian parameter estimation. For the prior, we'll use the Dirichlet distribution, which is defined over the set of probability vectors (i.e. vectors that are non negative and whose entries sum to 1). Its PDF is as follows:\n",
    "\n",
    "$$\n",
    "p(\\pmb{\\theta}) \\propto \\theta_{1}^{a_1-1} ... \\theta_{K}^{a_k-1}\n",
    "$$\n",
    "\n",
    "A useful fact is that if $\\pmb{\\theta} \\sim Dirichlet(a_1,...,a_k)$, then\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\theta_k] = \\frac{a_k}{\\sum_{k'} a_{k'}}\n",
    "$$\n",
    "\n",
    "Determine the posterior distribution $p(\\pmb{\\theta}|\\mathcal{D})$, where $\\mathcal{D}$ is the set of observations. From that, determine the posterior predictive probability that the next outcome will be $k$.\n",
    "\n",
    "##### Showing that the Dirichlet is Conjugate to the Categorical\n",
    "\n",
    "the full form of the dirichlet distribution (adapted from prince, bishop) is as follows:\n",
    "\n",
    "$$\n",
    "p(\\pmb{\\theta};\\mathbf{a}) =\n",
    "\\mathcal{c}(\\mathbf{a}) \\prod_{k=1}^{K} \\theta_{k}^{a_k - 1} =\n",
    "Dir_{\\pmb{\\theta}}[\\mathbf{a}]\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\mathcal{c}(\\mathbf{a}) = \n",
    "\\frac\n",
    "{\n",
    "\\Gamma(\\sum_{k=1}^K a_k)\n",
    "}\n",
    "{\n",
    "\\prod_{k=1}^K \\Gamma(a_k)\n",
    "}\n",
    "$$\n",
    "\n",
    "##### aside\n",
    "\n",
    "in all subsequent steps, we expand all the definitions in the numerator and denominator. it should be clear that the expressions in the numerator and denominator *do not change* and are only manipulated algebraically. the entire expression represents a particular instantiation of bayes rule:\n",
    "\n",
    "$$\n",
    "p(\\pmb{\\theta}|\\mathcal{D}) =\n",
    "\\frac\n",
    "{\n",
    "p(\\mathcal{D},\\pmb{\\theta})\n",
    "}\n",
    "{\n",
    "\\int_{\\pmb{\\theta}} p(\\mathcal{D},\\pmb{\\theta})\n",
    "}\n",
    "$$\n",
    "\n",
    "##### showing conjugacy\n",
    "\n",
    "our goal is too determine the posterior distribution over $K$ parameters given $I$ data (where each datum is one-hot encoding of class $k$):\n",
    "\n",
    "$$\n",
    "p(\\theta_1...\\theta_K|\\mathbf{x}_1...\\mathbf{x}_I)\n",
    "$$\n",
    "\n",
    "we expand this expression using bayes rule. the likelihood term for the data given the parameters is the same as defined in part 1a. the prior is a dirichlet distribution over $\\pmb{\\theta}$ which is parameterized by a vector $\\mathbf{a}$ whose components can take on arbitrary positive values.\n",
    "\n",
    "$$\n",
    "= \\frac\n",
    "{\n",
    "(\\prod_{i=1}^{I} Cat_{\\mathbf{x}^{(i)}} [\\pmb{\\theta}])\n",
    "(Dir_{\\pmb{\\theta}}[\\mathbf{a}])\n",
    "}\n",
    "{\n",
    "\\int_{\\theta}(\n",
    "(\\prod_{i=1}^{I} Cat_{\\mathbf{x}^{(i)}} [\\pmb{\\theta}])\n",
    "(Dir_{\\pmb{\\theta}}[\\mathbf{a}]))\n",
    "}\n",
    "$$\n",
    "\n",
    "we then expand the definitions further:\n",
    "\n",
    "$$\n",
    "= \\frac\n",
    "{\n",
    "(\\prod_{i=1}^{I} \\prod_{k=1}^K \\theta_{k}^{x_{k}^{(i)}})\n",
    "(\\mathcal{c}(\\mathbf{a}) \\prod_{k=1}^{K} \\theta_{k}^{a_k - 1})\n",
    "}\n",
    "{\n",
    "\\int_{\\theta}(\n",
    "(\\prod_{i=1}^{I} \\prod_{k=1}^K \\theta_{k}^{x_{k}^{(i)}})\n",
    "(\\mathcal{c}(\\mathbf{a}) \\prod_{k=1}^{K} \\theta_{k}^{a_k - 1}))\n",
    "}\n",
    "$$\n",
    "\n",
    "we know from part 1a of this homework that the likelihood term reduces to\n",
    "\n",
    "$$\n",
    "= \\frac\n",
    "{\n",
    "(\\prod_{k=1}^K \\theta_{k}^{N_k})\n",
    "(\\mathcal{c}(\\mathbf{a}) \\prod_{k=1}^{K} \\theta_{k}^{a_k - 1})\n",
    "}\n",
    "{\n",
    "\\int_{\\theta}(\n",
    "(\\prod_{k=1}^K \\theta_{k}^{N_k})\n",
    "(\\mathcal{c}(\\mathbf{a}) \\prod_{k=1}^{K} \\theta_{k}^{a_k - 1}))\n",
    "}\n",
    "$$\n",
    "\n",
    "where $N_k = \\sum_{i} x_k^{(i)}$. Next we use simple algebra to add exponents\n",
    "\n",
    "$$\n",
    "= \\frac\n",
    "{\n",
    "\\mathcal{c}(\\mathbf{a}) \\prod_{k=1}^{K} \\theta_{k}^{a_k - 1 + N_k}\n",
    "}\n",
    "{\n",
    "\\int_{\\theta}(\n",
    "\\mathcal{c}(\\mathbf{a}) \\prod_{k=1}^{K} \\theta_{k}^{a_k - 1 + N_k})\n",
    "}\n",
    "$$\n",
    "\n",
    "if we rearrage the terms in the exponent, we start to get a clearer picture of what is going on\n",
    "\n",
    "$$\n",
    "= \\frac\n",
    "{\n",
    "\\mathcal{c}(\\mathbf{a}) \\prod_{k=1}^{K} \\theta_{k}^{(a_k + N_k) - 1}\n",
    "}\n",
    "{\n",
    "\\int_{\\theta}(\n",
    "\\mathcal{c}(\\mathbf{a}) \\prod_{k=1}^{K} \\theta_{k}^{(a_k + N_k) - 1}\n",
    ")\n",
    "}\n",
    "$$\n",
    "\n",
    "lets define a new vector $\\widetilde{\\mathbf{a}}$ where \n",
    "$\\widetilde{a_k} = a_k + N_k$. now we introduce the following quantities into the expression of the posterior:\n",
    "\n",
    "$$\n",
    "= \n",
    "\\frac\n",
    "{\n",
    "c(\\mathbf{a}) \n",
    "\\frac{c(\\widetilde{\\mathbf{a}})}{c(\\widetilde{\\mathbf{a}})}\n",
    "\\prod_{k=1}^{K} \\theta_{k}^{\\widetilde{a_k} - 1}\n",
    "}\n",
    "{\n",
    "\\int_{\\theta}(\n",
    "c(\\mathbf{a}) \n",
    "\\frac{c(\\widetilde{\\mathbf{a}})}{c(\\widetilde{\\mathbf{a}})}\n",
    "\\prod_{k=1}^{K} \\theta_{k}^{\\widetilde{a_k} - 1}\n",
    ")\n",
    "}\n",
    "$$\n",
    "\n",
    "we reassociate terms to yield:\n",
    "\n",
    "$$\n",
    "= \n",
    "\\frac\n",
    "{\n",
    "\\frac {c(\\mathbf{a})} {c(\\widetilde{\\mathbf{a}})}\n",
    "c(\\widetilde{\\mathbf{a}})\n",
    "\\prod_{k=1}^{K} \\theta_{k}^{\\widetilde{a_k} - 1}\n",
    "}\n",
    "{\n",
    "\\int_{\\theta}(\n",
    "\\frac {c(\\mathbf{a})} {c(\\widetilde{\\mathbf{a}})}\n",
    "c(\\widetilde{\\mathbf{a}})\n",
    "\\prod_{k=1}^{K} \\theta_{k}^{\\widetilde{a_k} - 1}\n",
    ")\n",
    "}\n",
    "$$\n",
    "\n",
    "simplify notation\n",
    "\n",
    "$$\n",
    "= \n",
    "\\frac\n",
    "{\n",
    "\\frac {c(\\mathbf{a})} {c(\\widetilde{\\mathbf{a}})}\n",
    "Dir_{\\pmb{\\theta}}[\\widetilde{\\mathbf{a}}]\n",
    "}\n",
    "{\n",
    "\\int_{\\theta}(\n",
    "\\frac {c(\\mathbf{a})} {c(\\widetilde{\\mathbf{a}})}\n",
    "Dir_{\\pmb{\\theta}}[\\widetilde{\\mathbf{a}}]\n",
    ")\n",
    "}\n",
    "$$\n",
    "\n",
    "notice that the term $\\frac {c(\\mathbf{a})} {c(\\widetilde{\\mathbf{a}})}$ factors out of the integral and cancels with the term in the numerator\n",
    "\n",
    "$$\n",
    "= \n",
    "\\frac\n",
    "{\n",
    "Dir_{\\pmb{\\theta}}[\\widetilde{\\mathbf{a}}]\n",
    "}\n",
    "{\n",
    "\\int_{\\theta}(\n",
    "Dir_{\\pmb{\\theta}}[\\widetilde{\\mathbf{a}}]\n",
    ")\n",
    "}\n",
    "$$\n",
    "\n",
    "notice how the denomenator is an integral wrt to $\\pmb{\\theta}$ and the integrand is a distribution over $\\pmb{\\theta}$, so by the rules of probability, it must integrate to 1.\n",
    "\n",
    "$$\n",
    "= \n",
    "\\frac\n",
    "{\n",
    "Dir_{\\pmb{\\theta}}[\\widetilde{\\mathbf{a}}]\n",
    "}\n",
    "{\n",
    "1\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "= Dir_{\\pmb{\\theta}}[\\widetilde{\\mathbf{a}}]\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://blog.bogatron.net/blog/2014/02/02/visualizing-dirichlet-distributions/\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import scipy.stats as stats\n",
    "\n",
    "corners = np.array([[0, 0], [1, 0], [0.5, 0.75**0.5]])\n",
    "triangle = tri.Triangulation(corners[:, 0], corners[:, 1])\n",
    "refiner = tri.UniformTriRefiner(triangle)\n",
    "trimesh = refiner.refine_triangulation(subdiv=4)\n",
    "\n",
    "\n",
    "# Mid-points of triangle sides opposite of each corner\n",
    "midpoints = [(corners[(i + 1) % 3] + corners[(i + 2) % 3]) / 2.0 \\\n",
    "             for i in range(3)]\n",
    "def xy2bc(xy, tol=1.e-3):\n",
    "    '''Converts 2D Cartesian coordinates to barycentric.'''\n",
    "    s = [(corners[i] - midpoints[i]).dot(xy - midpoints[i]) / 0.75 \\\n",
    "         for i in range(3)]\n",
    "    return np.clip(s, tol, 1.0 - tol)\n",
    "\n",
    "class Dirichlet(object):\n",
    "    def __init__(self, alpha):\n",
    "        from math import gamma\n",
    "        from operator import mul\n",
    "        self._alpha = np.array(alpha)\n",
    "        self._coef = gamma(np.sum(self._alpha)) / \\\n",
    "                     reduce(mul, [gamma(a) for a in self._alpha])\n",
    "    def pdf(self, x):\n",
    "        '''Returns pdf value for `x`.'''\n",
    "        from operator import mul\n",
    "        return self._coef * reduce(mul, [xx ** (aa - 1)\n",
    "                                         for (xx, aa)in zip(x, self._alpha)])\n",
    "\n",
    "def draw_pdf_contours(dist, nlevels=200, subdiv=8, **kwargs):\n",
    "    import math\n",
    "\n",
    "    refiner = tri.UniformTriRefiner(triangle)\n",
    "    trimesh = refiner.refine_triangulation(subdiv=subdiv)\n",
    "    pvals = [dist.pdf(xy2bc(xy)) for xy in zip(trimesh.x, trimesh.y)]\n",
    "\n",
    "    plt.tricontourf(trimesh, pvals, nlevels, **kwargs)\n",
    "    plt.axis('equal')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 0.75**0.5)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d2290d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_pdf_contours2([1.,1.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkUxflbJnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ae1dbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_pdf_contours2([50,50,50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scratch\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_1 = (1,0,0) \\\\\n",
    "\\mathbf{x}_2 = (0,1,0) \\\\\n",
    "\\mathbf{x}_3 = (0,0,1) \\\\\n",
    "\\mathbf{x}_4 = (0,0,1)\n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\prod_{n=1}^{4} \\prod_{k=1}^3 \\theta_{k}^{x_{nk}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\prod_{n=1}^{4} ( (\\theta_{1}^{x_{n1}})(\\theta_{2}^{x_{n2}})(\\theta_{3}^{x_{n3}}) )\n",
    "$$\n",
    "\n",
    "$$\n",
    "(\\theta_{1}^{x_{11}})(\\theta_{2}^{x_{12}})(\\theta_{3}^{x_{13}})\n",
    "(\\theta_{1}^{x_{21}})(\\theta_{2}^{x_{22}})(\\theta_{3}^{x_{23}})\n",
    "(\\theta_{1}^{x_{31}})(\\theta_{2}^{x_{32}})(\\theta_{3}^{x_{33}})\n",
    "(\\theta_{1}^{x_{41}})(\\theta_{2}^{x_{42}})(\\theta_{3}^{x_{43}})\n",
    "$$\n",
    "\n",
    "$$\n",
    "(\\theta_{1}^1)(\\theta_{2}^0)(\\theta_{3}^0)\n",
    "(\\theta_{1}^0)(\\theta_{2}^1)(\\theta_{3}^0)\n",
    "(\\theta_{1}^0)(\\theta_{2}^0)(\\theta_{3}^1)\n",
    "(\\theta_{1}^0)(\\theta_{2}^0)(\\theta_{3}^1)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
